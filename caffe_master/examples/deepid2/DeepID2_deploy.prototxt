name: "DeepID2 deploy proto"
# 输入数据的batch size, channel, width, height
input: "data"
input_dim: 1
input_dim: 3
input_dim: 47
input_dim: 55

layer {
	name: "conv1"
	type: "Convolution"
	bottom: "data"
	top: "conv1"
	convolution_param {
		num_output: 20
		kernel_size: 4
		stride: 1
	}
}

layer {
	name: "relu1"
	type: "PReLU"
	bottom: "conv1"
	top: "conv1"
	prelu_param { 
		filler: { 
		    value: 0.33 #: 默认为0.25 
		} 
		channel_shared: false 
	} 
}

layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}

layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"

  convolution_param {
    num_output: 40
    kernel_size: 3
    stride: 1
 
  }
}

layer {
	name: "relu2"
	type: "PReLU"
	bottom: "conv2"
	top: "conv2"
	prelu_param { 
	filler: { 
	    value: 0.33 #: 默认为0.25 
	} 
	channel_shared: false 
	} 
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 1
  }
}

layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"

  convolution_param {
    num_output: 60
    kernel_size: 3
    stride: 1

  }
}

layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}

layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}

layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"

  convolution_param {
    num_output: 80
    kernel_size: 2
    stride: 1

  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}

layer {
  name: "fc160_1"
  type: "InnerProduct"
  bottom: "pool3"
  top: "fc160_1"

  inner_product_param {
    num_output: 160

  }
}

layer {
  name: "fc160_2"
  type: "InnerProduct"
  bottom: "conv4"
  top: "fc160_2"
  param {
    name: "fc160_2_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "fc160_2_b"
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 160
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}

layer {
  name: "fc160"
  type: "Eltwise"
  bottom: "fc160_1"
  bottom: "fc160_2"
  top: "fc160"
  eltwise_param {
    operation: SUM
  }
}

layer {
  name: "dropout"
  type: "Dropout"
  bottom: "fc160"
  top: "fc160"
  dropout_param {
    dropout_ratio: 0.5
  }
}
